# CRITICAL UNDERSTANDING: This entire script runs from TOP to BOTTOM on:
# 1. âœ… User opens the page (first visit)
# 2. âœ… User clicks ANY button 
# 3. âœ… User uploads a file
# 4. âœ… User types in text area
# 5. âœ… User selects from dropdown
# 6. âœ… User checks a checkbox
# 7. âœ… ANY user interaction that changes widget state

import streamlit as st
import pandas as pd
import warnings
import sys
import os

# Add current directory to path for imports
sys.path.append(os.path.dirname(__file__))

from causal.analyzer import CausalAnalyzer
from llm.llm import generate_domain_constraints, explain_results_with_llm
from ui.components import show_data_preview, show_data_quality_summary, show_correlation_heatmap, show_causal_graph, show_results_table, show_interactive_scenario_explorer

# Comprehensive warning suppression
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)
warnings.filterwarnings('ignore', category=DeprecationWarning)

# Configure page
st.set_page_config(
    page_title="Causal AI Platform", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# Professional CSS styling
st.markdown("""
<style>
    .main-container {
        max-width: 1200px;
        margin: 0 auto;
    }    .hero-section {
        text-align: center; 
        padding: 2.5rem 2rem; 
        background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 50%, #fecfef 100%); 
        border-radius: 15px; 
        margin-bottom: 2.5rem; 
        color: #2c3e50;
        box-shadow: 0 10px 30px rgba(255, 154, 158, 0.3);
    }    .hero-title {
        font-size: 2.8rem; 
        font-weight: 700; 
        margin-bottom: 0.8rem; 
        text-shadow: 1px 1px 3px rgba(0,0,0,0.15);
        letter-spacing: -0.02em;        color: #2c3e50;
    }    .hero-subtitle {
        font-size: 1.2rem; 
        font-weight: 400; 
        margin: 1rem 0 0 0; 
        opacity: 0.95; 
        line-height: 1.7;
        max-width: 95%;
        margin-left: auto;
        margin-right: auto;
        color: #2c3e50;
        text-align: center;
        padding: 0 1rem;
    }
    .step-header {
        background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
        padding: 1.2rem 1.5rem;
        border-left: 4px solid #e17055;
        border-radius: 0 10px 10px 0;
        margin: 2rem 0 1.5rem 0;
        box-shadow: 0 4px 15px rgba(252, 182, 159, 0.3);
    }
    .step-header h2 {
        margin: 0;
        color: #2c3e50;
        font-weight: 600;
    }
    .professional-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.08);
        border: 1px solid #e1e5e9;
        margin: 1rem 0;
    }    .stButton > button {
        background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
        color: #2c3e50;
        border: none;
        border-radius: 8px;
        padding: 0.6rem 1.5rem;
        font-weight: 500;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(255, 154, 158, 0.3);
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(255, 154, 158, 0.4);
    }    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #fff5f5 0%, #ffffff 100%);
    }
</style>
""", unsafe_allow_html=True)

# Initialize analyzer
@st.cache_resource
def get_analyzer():
    # This creates ONE shared analyzer instance for ALL users
    # But each user's data and results are kept separate via session_state
    return CausalAnalyzer()

analyzer = get_analyzer()

# Simple session state initialization - much cleaner than state machine
if 'causal_discovery_completed' not in st.session_state:
    st.session_state['causal_discovery_completed'] = False

if 'selected_treatment' not in st.session_state:
    st.session_state['selected_treatment'] = None

if 'selected_outcome' not in st.session_state:
    st.session_state['selected_outcome'] = None

if 'ate_results' not in st.session_state:
    st.session_state['ate_results'] = None

if 'domain_constraints_generated' not in st.session_state:
    st.session_state['domain_constraints_generated'] = False

if 'constraints_data' not in st.session_state:
    st.session_state['constraints_data'] = None

# Sidebar
with st.sidebar:
    st.markdown("### ğŸ”§ Configuration")
    
    # API Key input
    api_key = st.text_input(
        "OpenAI API Key", 
        type="password", 
        help="Required for LLM-guided domain constraints and insights",
        value=st.session_state.get('openai_api_key', '')
    )
    
    if api_key:
        st.session_state['openai_api_key'] = api_key
        st.success("âœ… API Key saved for this session")
    
    st.markdown("### ğŸ“‹ Analysis Steps")
    st.markdown("""
    1. Upload Excel/CSV file
    2. Configure domain constraints
    3. Run causal discovery
    4. Calculate treatment effects
    5. Get AI explanations
    """)

# Main interface with professional hero section
st.markdown("""
<div class="hero-section">
    <h1 class="hero-title">Causal AI Platform</h1>
    <p class="hero-subtitle">
        Discover causal relationships and quantify treatment effects with advanced AI-powered analysis. 
        Our platform combines cutting-edge algorithms with intelligent domain expertise to uncover hidden patterns, 
        measure intervention impacts, and deliver actionable insights for data-driven decision making.
    </p>
</div>
""", unsafe_allow_html=True)

# Step 1: Data Upload
st.markdown('<div class="step-header"><h2>ğŸ“ Step 1: Data Upload</h2></div>', unsafe_allow_html=True)

# Create two columns for upload options
col1, col2 = st.columns([1, 1])

with col1:
    st.markdown("### ğŸ“¤ Upload Your Own Data")
    uploaded_file = st.file_uploader(
        "Upload your Excel or CSV file",
        type=['xlsx', 'csv'],
        help="Ensure your data has clean column names and numeric values."
    )

with col2:
    st.markdown("### ğŸ“Š Use Sample Dataset")
    
    # Get list of sample data files
    sample_data_dir = os.path.join(os.path.dirname(__file__), 'sample_data')
    sample_files = []
    sample_descriptions = {
        'medical_study.csv': 'ğŸ¥ Medical Treatment Study (Recovery Time Analysis)',
        'marketing_campaign.csv': 'ğŸ“ˆ Marketing ROI Analysis (Ad Spend vs Sales)',
        'education_study.csv': 'ğŸ“ Education Study (Study Hours vs Test Scores)'
    }
    
    if os.path.exists(sample_data_dir):
        for file in os.listdir(sample_data_dir):
            if file.endswith('.csv'):
                sample_files.append(file)
    
    if sample_files:
        selected_sample = st.selectbox(
            "Choose a sample dataset:",
            options=['None'] + sample_files,
            format_func=lambda x: 'Select a dataset...' if x == 'None' else sample_descriptions.get(x, x),
            help="These datasets demonstrate different causal relationships and include realistic confounding factors."
        )
        
        if selected_sample != 'None':
            sample_file_path = os.path.join(sample_data_dir, selected_sample)
            if st.button("Load Sample Dataset", key="load_sample"):
                try:
                    # Load the sample data
                    sample_data = pd.read_csv(sample_file_path)
                    analyzer.data = sample_data
                    
                    # Set session state
                    st.session_state['data_loaded'] = True
                    st.session_state['causal_discovery_completed'] = False
                    st.session_state['sample_data_loaded'] = selected_sample
                    
                    st.success(f"âœ… Sample dataset '{selected_sample}' loaded successfully!")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ Error loading sample dataset: {str(e)}")
    else:
        st.info("No sample datasets found. Run `python create_sample_data.py` to generate sample datasets.")

# Handle uploaded file
data_source = None
if uploaded_file:
    if analyzer.load_data(uploaded_file):
        # ğŸš¦ STATE TRANSITION: Data uploaded
        st.session_state['data_loaded'] = True
        st.session_state['causal_discovery_completed'] = False
        st.session_state.pop('sample_data_loaded', None)  # Clear sample data flag
        data_source = f"Uploaded file: {uploaded_file.name}"
        
        st.success("âœ… Data loaded successfully!")
elif st.session_state.get('sample_data_loaded'):
    data_source = f"Sample dataset: {st.session_state['sample_data_loaded']}"

# Show data info if data is loaded
if st.session_state.get('data_loaded') and analyzer.data is not None:
    
    # Show data source info
    if data_source:
        st.info(f"ğŸ“Š **Data Source**: {data_source}")
    
    # Display data preview and quality summary
    show_data_preview(analyzer.data)
    show_data_quality_summary(analyzer.data)
    
    # Add sample dataset information if applicable
    if st.session_state.get('sample_data_loaded'):
        sample_name = st.session_state['sample_data_loaded']
        
        # Show sample dataset description
        if sample_name == 'medical_study.csv':
            st.info("""
            ğŸ¥ **Medical Treatment Study**: This dataset examines the effect of a medical treatment on patient recovery time. 
            Key variables include patient age, disease severity, treatment status, and recovery days. 
            The goal is to determine if the treatment reduces recovery time while controlling for confounding factors.
            """)
        elif sample_name == 'marketing_campaign.csv':
            st.info("""
            ğŸ“ˆ **Marketing ROI Analysis**: This dataset analyzes the relationship between advertising spend and sales performance. 
            Variables include monthly ad spend, market conditions, seasonality effects, and sales revenue. 
            The goal is to measure the return on advertising investment.
            """)
        elif sample_name == 'education_study.csv':
            st.info("""
            ğŸ“ **Education Effectiveness Study**: This dataset studies the impact of study time on student performance. 
            Variables include student IQ, motivation level, weekly study hours, and test scores. 
            The goal is to quantify how additional study time improves academic performance.
            """)

    # Step 2: Domain Constraints
    st.markdown('<div class="step-header"><h2>ğŸ§  Step 2: Domain Constraints (AI-Powered)</h2></div>', unsafe_allow_html=True)
    
    domain_context = st.text_area(
        "Describe your domain/business context:",
        placeholder="e.g., 'This is customer behavior data where age comes before purchase decisions...'",
        height=100
    )
    
    if st.button("ğŸ¤– Generate Domain Constraints", type="secondary"):
        if domain_context:
            with st.spinner("AI is analyzing your domain..."):
                constraints = generate_domain_constraints(
                    list(analyzer.data.columns), 
                    domain_context,
                    st.session_state.get('openai_api_key')
                )                
            if constraints and constraints.get('explanation') != "No API key provided":
                # Validate constraints for conflicts
                from causal.discovery_constraints import validate_constraints
                validation = validate_constraints(constraints)                    
                if validation['conflicts']:
                    st.warning("âš ï¸ Constraint conflicts detected - they will be automatically resolved")
                    for conflict in validation['conflicts']:
                        st.warning(f"ğŸš¨ {conflict['description']} â†’ Required edge will take precedence")
                    st.session_state['constraints_data'] = validation['resolved_constraints']
                    resolved_constraints = validation['resolved_constraints']
                else:
                    st.success("âœ… Domain constraints generated!")
                    st.session_state['constraints_data'] = constraints
                    resolved_constraints = constraints
                
                if validation['warnings']:
                    for warning in validation['warnings']:
                        st.info(f"ğŸ’¡ {warning}")
                
                st.session_state['domain_constraints_generated'] = True
                
                col1, col2 = st.columns(2)
                with col1:
                    display_constraints = resolved_constraints
                    st.json(display_constraints)
                with col2:
                    st.info(f"**Explanation:** {constraints.get('explanation', 'No explanation provided')}")
                
                analyzer.domain_constraints = resolved_constraints
            else:
                st.error("âŒ Failed to generate constraints. Check your API key.")
        else:
            st.warning("Please provide domain context first.")
    
    # Show previously generated constraints
    if st.session_state.get('domain_constraints_generated') and st.session_state.get('constraints_data'):
        with st.expander("ğŸ“‹ Current Domain Constraints", expanded=False):
            st.json(st.session_state['constraints_data'])
    
    # Step 3: Causal Discovery
    st.markdown('<div class="step-header"><h2>ğŸ” Step 3: Causal Discovery</h2></div>', unsafe_allow_html=True)
    
    # Add validation for constraints
    constraints_ready = (
        st.session_state.get('domain_constraints_generated') or 
        st.checkbox("Skip AI constraints (use default)", help="Run discovery without AI-generated constraints")
    )
    
    if st.button("ğŸš€ Run Causal Discovery", type="primary", disabled=not constraints_ready):
        with st.spinner("Discovering causal relationships..."):
            active_constraints = st.session_state.get('constraints_data', {})
            success = analyzer.run_causal_discovery(active_constraints)
            
        if success:
            st.session_state['causal_discovery_completed'] = True
            st.success("âœ… Causal discovery completed!")
            
            if active_constraints:
                st.info(f"ğŸ§  Used AI constraints: {len(active_constraints.get('forbidden_edges', []))} forbidden edges, {len(active_constraints.get('required_edges', []))} required edges")
        else:
            st.session_state['causal_discovery_completed'] = False
            st.error("âŒ Causal discovery failed")
    
    # Show causal discovery results
    if st.session_state['causal_discovery_completed'] and analyzer.adjacency_matrix is not None:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ“ˆ Discovered Causal Graph")
            show_causal_graph(analyzer.adjacency_matrix, list(analyzer.data.columns))
        
        with col2:
            st.subheader("ğŸ“Š Adjacency Matrix")
            adj_df = pd.DataFrame(
                analyzer.adjacency_matrix, 
                index=analyzer.data.columns, 
                columns=analyzer.data.columns
            )
            st.dataframe(adj_df.round(3))
    
    # Step 4: Variable Relationship Analysis
    st.markdown('<div class="step-header"><h2>ğŸ“Š Step 4: Variable Relationship Analysis</h2></div>', unsafe_allow_html=True)
    
    if st.button("ğŸ” Analyze Variable Relationships", type="secondary"):
        with st.spinner("Analyzing variable relationships..."):
            relationships = analyzer.analyze_variable_relationships()
            
            if relationships:
                st.success("âœ… Relationship analysis completed!")
                
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.subheader("ğŸ”¥ Correlation Heatmap")
                    show_correlation_heatmap(relationships['correlation_matrix'])
                
                with col2:
                    st.subheader("ğŸ’ª Strongest Correlations")
                    strong_corr = relationships['strong_correlations']
                    if strong_corr:
                        for corr in strong_corr[:5]:
                            st.write(f"**{corr['var1']}** â†” **{corr['var2']}**: {corr['correlation']:.3f}")
                    else:
                        st.write("No strong correlations (>0.5) found")
    
    # Step 5: Causal Inference Analysis
    st.markdown('<div class="step-header"><h2>ğŸ”¬ Step 5: Causal Inference Analysis</h2></div>', unsafe_allow_html=True)
    
    if analyzer.data is not None and not analyzer.data.empty:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            treatment_var = st.selectbox(
                "Treatment Variable (Cause)",
                options=list(analyzer.data.columns),
                key="treatment_select"
            )
        
        with col2:
            outcome_var = st.selectbox(
                "Outcome Variable (Effect)", 
                options=[col for col in analyzer.data.columns if col != treatment_var],
                key="outcome_select"
            )
        
        with col3:
            confounders = st.multiselect(
                "Confounding Variables",
                options=[col for col in analyzer.data.columns if col not in [treatment_var, outcome_var]],
                key="confounders_select"
            )
        
        if st.button("ğŸ”¬ Run Causal Inference", type="primary"):
            if treatment_var != outcome_var:
                with st.spinner("Running causal inference..."):
                    ate_results = analyzer.calculate_ate(treatment_var, outcome_var, confounders)
                    st.session_state['ate_results'] = ate_results
                    st.session_state['selected_treatment'] = treatment_var
                    st.session_state['selected_outcome'] = outcome_var
            else:
                st.error("âŒ Please select different variables for treatment and outcome")
    
    # Display results
    if st.session_state.get('ate_results'):
        ate_results = st.session_state['ate_results']
        treatment_var = st.session_state['selected_treatment']
        outcome_var = st.session_state['selected_outcome']
        
        st.success("âœ… Causal inference completed!")
          # Main result
        st.subheader("ğŸ“Š Main Result")
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.metric(
                "Causal Effect Estimate", 
                f"{ate_results['consensus_estimate']:.4f}"
            )
        
        with col2:
            st.info(f"**Interpretation:** {ate_results['interpretation']}")
        
        # Detailed results
        st.subheader("ğŸ” Detailed Results by Method")
        show_results_table(ate_results)        # Interactive Policy Scenarios
        st.markdown('<div class="step-header"><h2>ğŸ® Interactive Policy Explorer</h2></div>', unsafe_allow_html=True)
        show_interactive_scenario_explorer(ate_results, treatment_var, outcome_var, analyzer)
        
        # AI Explanation - IMPROVED INTEGRATION
        st.markdown('<div class="step-header"><h2>ğŸ§  AI-Powered Insights</h2></div>', unsafe_allow_html=True)
        
        # Show button only if API key is available
        if st.session_state.get('openai_api_key'):
            if st.button("ğŸ¤– Get Detailed AI Analysis", type="secondary"):
                with st.spinner("AI is analyzing your results..."):
                    explanation = explain_results_with_llm(
                        ate_results, treatment_var, outcome_var,
                        st.session_state.get('openai_api_key')
                    )
                
                st.markdown("### ğŸ“‹ Business Insights & Recommendations")
                st.markdown(explanation)
        else:
            st.warning("ğŸ”‘ Add OpenAI API key in sidebar to get AI-powered explanations")

else:
    # Landing page when no file is uploaded
    st.info("""
    ğŸ‘† **Get Started:** Upload your Excel or CSV file above to begin causal analysis.
    
    **What you can do with this platform:**
    - ğŸ” Discover causal relationships in your data
    - ğŸ“Š Calculate treatment effects with confidence intervals
    - ğŸ¤– Get AI-powered insights and recommendations
    - ğŸ¯ Simulate policy interventions
    """)
